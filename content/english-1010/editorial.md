---
title: "Editorial"
date: 2022-10-20T12:47:22-07:00
---

**Texas Social Media Censorship Law**

The Supreme Court blocked a Texas law from being passed. This law would ban large social media companies from blocking posts based on their views. This would include posts such as "Russia’s propaganda claiming that its invasion of Ukraine is justified, ISIS propaganda claiming that extremism is warranted, neo-Nazi or K.K.K." (Liptak) Lucio Vasquez from Houston Public Media states that the bill was introduced after several conservatives, including Donald Trump, were banned from these platforms. These companies claim it was because of the violation of their terms of service. Texas believes that these platforms are suppressing the political views of conservatives. Judge Pitman wrote that the first amendment protects the rights of social media companies to moderate content on their platforms. Along with the removal of moderation, this law also proposes that users can sue these platforms if they believe they’ve been censored by their political views.

I agree with Judge Pitman’s statement. I believe these platforms reserve the right to moderate the content on their platforms. This right is held under the first amendment of the constitution. But I don’t agree with the amount of moderation that these platforms enforce. Ideally, these companies wouldn’t overuse this power. Social media companies state that they regulate their content based on their terms of service. I support regulation of content through this aspect, only if the content moderation is clearly stated in the terms of service. What’s allowed on the platform and what isn’t needs to be clear.

Kari Paul from The Guardian states that the passage of this Texas law came from conservatives and "rightwing commentators" complaining about these platforms suppressing their views. This law is heavily motivated by politics. I don’t agree that these platforms are actively trying to suppress the views of one party over another. But I do believe that there’s definitely manipulation in terms of politics, especially during elections on these platforms.

At the end of the day, it’s their platform. They get to choose how they handle moderation. Some may argue that this would inhibit people’s rights to free speech. I disagree. I believe this action doesn’t affect people’s rights to free speech. If someone says something I don’t approve of in my house, I reserve the right to kick them out. These platforms hold that same right. People will still maintain freedom of speech, but their speech may have consequences based on their location. Ultimately, people can choose to move to another platform. Users are actively making the choice to inhibit their free speech by using these platforms.

"Research shows false news peaked on Twitter during the 2012 and 2016 presidential elections" (Brown) The MIT research concludes that misinformation is often heavily increased during the election season. If you allow users to have freedom of speech, there will always be misinformation. Many would conclude that it’s okay to block and censor this type of content. I would argue that it isn’t always black or white. To some, the information may be false, and to others it may be a reliable source. The beliefs and ideals of a company may differ from yours.

These platforms handle their moderation through their terms of service. The user agrees to these terms upon signing up. The user can be censored and blocked from the platform if they violate these terms. They have no right to argue with what they accepted when signing up for the platform.

A solution to this social media censorship problem would be for these companies to be transparent. I believe that moderation of content extends much further than simply blocking posts or users. The act of promoting certain topics or types of content over others is a form of censorship and moderation. These companies need to be transparent with the algorithms used to promote content. Users can be fooled into believing that their speech isn’t being censored or moderated; but in actuality, these platforms are suppressing their views. Algorithmic transparency would help to solve this issue. However, solving this wouldn’t solve the misinformation issue.

A possible solution to the misinformation issue would be to allow users to report posts that they believe to be misinformation. That way, the general public can agree on what is misinformation and what is not. The beliefs of a platform or company wouldn’t be pushed onto the users. But in the end, it’s still up to the company. They get to choose how to handle this problem. Right now, they are handling it with moderation and censorship, rather than community agreement. If you don’t want to be censored, move to a platform that you control.

**Works Cited**

Brown, Sara. “MIT Sloan research about social media, misinformation, and elections.” MIT
Sloan, 5 October 2020,
https://mitsloan.mit.edu/ideas-made-to-matter/mit-sloan-research-about-social-media-mis
information-and-elections. Accessed 16 October 2022.

Liptak, Adam. “Supreme Court Blocks Texas Law Regulating Social Media Platforms.” The
New York Times, 31 May 2022,
https://www.nytimes.com/2022/05/31/us/politics/supreme-court-social-media-texas.html.
Accessed 10 October 2022.

Paul, Kari. “US supreme court blocks Texas law targeting social media rules.” The Guardian, 1
June 2022,
https://www.theguardian.com/media/2022/may/31/texas-social-media-law-supreme-court
. Accessed 10 October 2022.

Vasquez, Lucio, et al. “The U.S. Supreme Court has once again blocked Texas' controversial
social media law – Houston Public Media.” Houston Public Media, 31 May 2022,
https://www.houstonpublicmedia.org/articles/news/politics/2022/05/31/426202/the-u-s-su
preme-court-is-once-again-blocking-texas-controversial-social-media-law/. Accessed 10
October 2022.
